# CUSTOM FILE: è«–æ–‡å¯¦ç¾æŒ‡å— - Illustrator's Depth

åƒè€ƒè«–æ–‡ï¼š[Illustrator's Depth: Monocular Layer Index Prediction for Image Decomposition](https://www.alphaxiv.org/abs/2511.17454)

## ğŸ¯ å¯¦ç¾å°é½Šç¢ºèª

### âœ… å®Œå…¨ç¬¦åˆè«–æ–‡çš„ä¸‰å€‹æ ¸å¿ƒè¦æ±‚

#### 1. æ¨¡å‹åˆå§‹åŒ–ï¼ˆInitializationï¼‰

**è«–æ–‡æ–¹æ³•**ï¼š
- è¼‰å…¥ Depth-Pro é è¨“ç·´æ¬Šé‡
- ä¿ç•™ Encoder (DINO-v2) å’Œ Decoder æ¶æ§‹
- ç§»é™¤ FOV headï¼ˆä¸éœ€è¦çœŸå¯¦ä¸–ç•Œå°ºåº¦ï¼‰

**æˆ‘å€‘çš„å¯¦ç¾**ï¼š
```python
# custom_layer_order_model.py ç¬¬ 150-167 è¡Œ
if config.checkpoint_uri is not None:
    state_dict = torch.load(config.checkpoint_uri, map_location="cpu")
    missing_keys, unexpected_keys = model.load_state_dict(
        state_dict=state_dict, strict=False  # å…è¨± FOV head æ¬Šé‡ä¸åŒ¹é…
    )
```

**å°é½Šç‹€æ…‹**ï¼šâœ… **å®Œå…¨ç¬¦åˆ**

---

#### 2. å·®ç•°åŒ–å­¸ç¿’ç‡ï¼ˆDifferential Learning Ratesï¼‰

**è«–æ–‡æ–¹æ³•**ï¼š
- Encoder (DINO-v2): è¼ƒä½å­¸ç¿’ç‡ï¼Œä¿ç•™é è¨“ç·´ç‰¹å¾µ
- Decoder + Head: è¼ƒé«˜å­¸ç¿’ç‡ï¼Œå¿«é€Ÿé©æ‡‰æ–°ä»»å‹™

**æˆ‘å€‘çš„å¯¦ç¾**ï¼š
```python
# custom_layer_order_train.py ç¬¬ 70-142 è¡Œ
encoder_params = []  # Encoder åƒæ•¸
decoder_params = []  # Decoder + Head åƒæ•¸

param_groups = [
    {'params': encoder_params, 'lr': encoder_lr},  # 1e-5
    {'params': decoder_params, 'lr': decoder_lr},  # 1e-4
]
```

**å°é½Šç‹€æ…‹**ï¼šâœ… **å®Œå…¨ç¬¦åˆ**

---

#### 3. Scale-Invariant Loss

**è«–æ–‡æ–¹æ³•**ï¼š
- ç›´æ¥é æ¸¬åœ–å±¤ç´¢å¼•ï¼ˆä¸é æ¸¬ inverse depthï¼‰
- ä½¿ç”¨ Scale-Invariant MAE Loss
- æ¨™æº–åŒ–ï¼š$\hat{d} = \frac{d - m}{s}$ï¼ˆm=ä¸­ä½æ•¸, s=MADï¼‰

**æˆ‘å€‘çš„å¯¦ç¾**ï¼š
```python
# custom_layer_order_loss.py ç¬¬ 14-99 è¡Œ
def scale_shift_invariant_loss(pred, target, eps=1e-6):
    # å°æ¯å¼µåœ–åˆ†åˆ¥æ¨™æº–åŒ–
    m_pred = torch.median(pred_b)
    s_pred = torch.mean(torch.abs(pred_b - m_pred)) + eps
    pred_norm = (pred_b - m_pred) / s_pred
    
    # åŒæ¨£è™•ç† target
    m_target = torch.median(target_b)
    s_target = torch.mean(torch.abs(target_b - m_target)) + eps
    target_norm = (target_b - m_target) / s_target
    
    # MAE Loss
    loss = torch.mean(torch.abs(pred_norm - target_norm))
```

**å°é½Šç‹€æ…‹**ï¼šâœ… **å®Œå…¨ç¬¦åˆ**

---

## ğŸ“ æ¨¡å‹æ¶æ§‹ç´°ç¯€

### Head çµæ§‹ï¼ˆç¬¦åˆè«–æ–‡ï¼‰

```python
self.head = nn.Sequential(
    nn.Conv2d(dim_decoder, dim_decoder // 2, ...),      # 256 -> 128
    nn.ConvTranspose2d(..., kernel_size=2, stride=2),  # ä¸Šæ¡æ¨£ 2x
    nn.Conv2d(128, 32, ...),                           # 128 -> 32
    nn.ReLU(True),
    nn.Conv2d(32, 1, kernel_size=1, ...),              # 32 -> 1
    nn.Sigmoid(),  # ç¢ºä¿è¼¸å‡ºåœ¨ [0, 1]
)
```

**é—œéµé»**ï¼š
- âœ… æœ€å¾Œä¸€å±¤æ˜¯ 1 é€šé“ï¼ˆåœ–å±¤ç´¢å¼•ï¼‰
- âœ… ä½¿ç”¨ Sigmoid ç¢ºä¿è¼¸å‡ºåœ¨ [0, 1]
- âœ… æœ€å¾Œä¸€å±¤ bias åˆå§‹åŒ–ç‚º 0ï¼ˆæ·±åº¦ä¼°è¨ˆçš„å¸¸è¦‹æŠ€å·§ï¼‰

---

## ğŸ”§ è¨“ç·´é…ç½®ï¼ˆç¬¦åˆè«–æ–‡ï¼‰

### å­¸ç¿’ç‡è¨­ç½®

```python
encoder_lr = 1e-5   # Encoder: è¼ƒä½å­¸ç¿’ç‡
decoder_lr = 1e-4   # Decoder: è¼ƒé«˜å­¸ç¿’ç‡ï¼ˆ10å€ï¼‰
```

**æ¯”ä¾‹**ï¼šEncoder:Decoder = 1:10 âœ…

### å„ªåŒ–å™¨

```python
optimizer = AdamW(
    param_groups,  # å…©å€‹åƒæ•¸çµ„
    weight_decay=1e-4,
)
```

### å­¸ç¿’ç‡èª¿åº¦å™¨

```python
scheduler = CosineAnnealingLR(
    optimizer,
    T_max=num_epochs,  # æ ¹æ“šå¯¦éš› epoch æ•¸èª¿æ•´
)
```

---

## ğŸ“Š æå¤±å‡½æ•¸ï¼ˆå®Œå…¨ç¬¦åˆè«–æ–‡ï¼‰

### Scale-Invariant MAE Loss

**æ•¸å­¸å…¬å¼**ï¼ˆè«–æ–‡ä¸­çš„å…¬å¼ï¼‰ï¼š
$$
\hat{d} = \frac{d - m}{s}
$$

$$
L_{MAE} = |\hat{D}_{pred} - \hat{D}_{gt}|
$$

å…¶ä¸­ï¼š
- $m$ = ä¸­ä½æ•¸ (median)
- $s$ = å¹³å‡çµ•å°åå·® (Mean Absolute Deviation, MAD)

**æˆ‘å€‘çš„å¯¦ç¾**ï¼š
```python
# å°æ¯å¼µåœ–åˆ†åˆ¥è¨ˆç®—
m_pred = torch.median(pred_b)
s_pred = torch.mean(torch.abs(pred_b - m_pred)) + eps
pred_norm = (pred_b - m_pred) / s_pred

# åŒæ¨£è™•ç† target
m_target = torch.median(target_b)
s_target = torch.mean(torch.abs(target_b - m_target)) + eps
target_norm = (target_b - m_target) / s_target

# MAE Loss
loss = torch.mean(torch.abs(pred_norm - target_norm))
```

**å°é½Šç‹€æ…‹**ï¼šâœ… **å®Œå…¨ç¬¦åˆè«–æ–‡å…¬å¼**

---

## ğŸš€ å®Œæ•´è¨“ç·´å‘½ä»¤

### åŸºæœ¬è¨“ç·´

```bash
cd /tmp2/b12902041/Gino/DLCV/final/ml-depth-pro

python custom_layer_order_train.py \
    --data-dir ../parsed_dataset \
    --checkpoint-path ./checkpoints/depth_pro.pt \
    --batch-size 4 \
    --num-epochs 100 \
    --learning-rate 1e-4 \
    --encoder-lr 1e-5 \
    --weight-decay 1e-4 \
    --use-edge-loss \
    --edge-loss-weight 0.1 \
    --save-dir ./checkpoints/layer_order \
    --num-workers 4
```

### åƒæ•¸èªªæ˜

| åƒæ•¸ | å€¼ | èªªæ˜ |
|------|-----|------|
| `--data-dir` | `../parsed_dataset` | è§£æå¾Œçš„è³‡æ–™é›†ç›®éŒ„ |
| `--checkpoint-path` | `./checkpoints/depth_pro.pt` | Depth-Pro é è¨“ç·´æ¬Šé‡ |
| `--batch-size` | `4` | æ‰¹æ¬¡å¤§å°ï¼ˆæ ¹æ“š GPU è¨˜æ†¶é«”èª¿æ•´ï¼‰ |
| `--learning-rate` | `1e-4` | Decoder å­¸ç¿’ç‡ |
| `--encoder-lr` | `1e-5` | Encoder å­¸ç¿’ç‡ï¼ˆè¼ƒä½ï¼‰ |
| `--use-edge-loss` | - | ä½¿ç”¨é‚Šç·£ä¿æŒæå¤±ï¼ˆå¯é¸ï¼‰ |
| `--edge-loss-weight` | `0.1` | é‚Šç·£æå¤±æ¬Šé‡ |

---

## ğŸ“‹ å¯¦ç¾æª¢æŸ¥æ¸…å–®

### æ¨¡å‹æ¶æ§‹
- [x] è¼‰å…¥ Depth-Pro é è¨“ç·´æ¬Šé‡
- [x] ä¿ç•™ Encoder (DINO-v2) æ¶æ§‹
- [x] ä¿ç•™ Decoder æ¶æ§‹
- [x] ç§»é™¤ FOV head
- [x] è¼¸å‡ºæ”¹ç‚ºå–®é€šé“åœ–å±¤ç´¢å¼•
- [x] ä½¿ç”¨ Sigmoid ç¢ºä¿è¼¸å‡ºåœ¨ [0, 1]
- [x] æœ€å¾Œä¸€å±¤ bias åˆå§‹åŒ–ç‚º 0

### è¨“ç·´ç­–ç•¥
- [x] å¯¦ç¾å·®ç•°åŒ–å­¸ç¿’ç‡
- [x] Encoder å­¸ç¿’ç‡ï¼š1e-5
- [x] Decoder å­¸ç¿’ç‡ï¼š1e-4
- [x] ä½¿ç”¨ AdamW å„ªåŒ–å™¨
- [x] ä½¿ç”¨ CosineAnnealingLR èª¿åº¦å™¨
- [x] å¯¦ç¾æ¢¯åº¦è£å‰ª

### æå¤±å‡½æ•¸
- [x] å¯¦ç¾ Scale-Invariant Loss
- [x] ä½¿ç”¨ä¸­ä½æ•¸é€²è¡Œæ¨™æº–åŒ–
- [x] ä½¿ç”¨ MAD é€²è¡Œæ¨™æº–åŒ–
- [x] è¨ˆç®—æ¨™æº–åŒ–å¾Œçš„ MAE
- [x] å¯é¸ï¼šé‚Šç·£ä¿æŒæå¤±

### è³‡æ–™è™•ç†
- [x] ç”Ÿæˆåœ–å±¤ç´¢å¼•åœ–ï¼ˆGTï¼‰
- [x] æ­¸ä¸€åŒ–åˆ° [0, 1]ï¼ˆèƒŒæ™¯=0ï¼Œå‰æ™¯=1ï¼‰
- [x] è™•ç†åœ–å±¤ç–ŠåŠ é †åº
- [x] è™•ç†é€æ˜å€åŸŸ

---

## ğŸ“ èˆ‡è«–æ–‡çš„å°æ‡‰é—œä¿‚

| è«–æ–‡è¦æ±‚ | æˆ‘å€‘çš„å¯¦ç¾ | æª”æ¡ˆä½ç½® |
|---------|----------|---------|
| è¼‰å…¥é è¨“ç·´æ¬Šé‡ | âœ… | `custom_layer_order_model.py:150-167` |
| å·®ç•°åŒ–å­¸ç¿’ç‡ | âœ… | `custom_layer_order_train.py:70-142` |
| Scale-Invariant Loss | âœ… | `custom_layer_order_loss.py:14-99` |
| ç§»é™¤ FOV head | âœ… | `custom_layer_order_model.py:131, 243` |
| è¼¸å‡º [0, 1] åœ–å±¤ç´¢å¼• | âœ… | `custom_layer_order_model.py:233` |
| è³‡æ–™é›†è™•ç† | âœ… | `custom_layer_order_dataset.py` |

---

## âš ï¸ æ³¨æ„äº‹é …

1. **è³‡æ–™é›†æ ¼å¼**ï¼š
   - ç¢ºä¿ä½¿ç”¨ `parsed_dataset` ç›®éŒ„ï¼ˆå·²è§£æçš„è³‡æ–™ï¼‰
   - æˆ–ä¿®æ”¹ `custom_layer_order_dataset.py` ä»¥é©é…æ‚¨çš„è³‡æ–™æ ¼å¼

2. **GPU è¨˜æ†¶é«”**ï¼š
   - 1536x1536 è¼¸å…¥éœ€è¦è¼ƒå¤§ GPU è¨˜æ†¶é«”
   - å¦‚æœè¨˜æ†¶é«”ä¸è¶³ï¼Œå¯ä»¥ï¼š
     - æ¸›å° batch_size
     - ä½¿ç”¨æ··åˆç²¾åº¦è¨“ç·´ï¼ˆ`--use-amp`ï¼‰

3. **å­¸ç¿’ç‡èª¿æ•´**ï¼š
   - å¦‚æœè¨“ç·´ä¸ç©©å®šï¼Œå¯ä»¥é™ä½å­¸ç¿’ç‡
   - å¦‚æœæ”¶æ–‚å¤ªæ…¢ï¼Œå¯ä»¥é©ç•¶æé«˜å­¸ç¿’ç‡

4. **æå¤±æ¬Šé‡**ï¼š
   - é‚Šç·£æå¤±æ¬Šé‡ï¼ˆ`edge_loss_weight`ï¼‰å¯ä»¥æ ¹æ“šæ•ˆæœèª¿æ•´
   - å¦‚æœé‚Šç·£ä¸å¤ éŠ³åˆ©ï¼Œå¯ä»¥å¢åŠ æ¬Šé‡

---

## ğŸ“š åƒè€ƒè³‡æ–™

- **è«–æ–‡**ï¼š[Illustrator's Depth: Monocular Layer Index Prediction for Image Decomposition](https://www.alphaxiv.org/abs/2511.17454)
- **Depth-Pro è«–æ–‡**ï¼šSharp Monocular Metric Depth in Less Than a Second
- **MiDaS è«–æ–‡**ï¼šTowards Robust Monocular Depth Estimation

---

## âœ… ç¸½çµ

**æˆ‘å€‘çš„å¯¦ç¾å®Œå…¨ç¬¦åˆè«–æ–‡çš„æ–¹æ³•**ï¼š

1. âœ… **æ¨¡å‹åˆå§‹åŒ–**ï¼šè¼‰å…¥ Depth-Pro é è¨“ç·´æ¬Šé‡ï¼Œä¿ç•™æ¶æ§‹ï¼Œç§»é™¤ FOV
2. âœ… **å·®ç•°åŒ–å­¸ç¿’ç‡**ï¼šEncoder 1e-5ï¼ŒDecoder 1e-4
3. âœ… **Scale-Invariant Loss**ï¼šä½¿ç”¨ä¸­ä½æ•¸å’Œ MAD é€²è¡Œæ¨™æº–åŒ–ï¼Œè¨ˆç®— MAE

å¯ä»¥ç›´æ¥ä½¿ç”¨æä¾›çš„è¨“ç·´å‘½ä»¤é–‹å§‹è¨“ç·´ï¼




