# LLaVA ç’°å¢ƒå®‰è£æŒ‡å—

## ğŸ“‹ æ–¹æ¡ˆé¸æ“‡

æ ¹æ“šä½ çš„æƒ…æ³ï¼Œæœ‰å…©å€‹æ–¹æ¡ˆï¼š

### æ–¹æ¡ˆ A: ä½¿ç”¨ç¾æœ‰çš„ LLaVA ç’°å¢ƒï¼ˆå¦‚æœå·²å­˜åœ¨ï¼‰
å¦‚æœ `/tmp2/b12902041/Gino/dlcv-fall-2025-final-project/` ä¸­å·²ç¶“æœ‰ LLaVAï¼Œå¯ä»¥ç›´æ¥ä½¿ç”¨ã€‚

### æ–¹æ¡ˆ B: å…¨æ–°å®‰è£ LLaVAï¼ˆæ¨è–¦ï¼‰
åœ¨ä½ è‡ªå·±çš„ç›®éŒ„ä¸‹å®‰è£ LLaVAã€‚

---

## ğŸš€ æ–¹æ¡ˆ B: å…¨æ–°å®‰è£ LLaVAï¼ˆæ¨è–¦ï¼‰

### Step 1: å‰µå»º conda ç’°å¢ƒ

```bash
# å‰µå»ºæ–°ç’°å¢ƒï¼ˆPython 3.10ï¼‰
conda create -n llava15 python=3.10 -y

# å•Ÿå‹•ç’°å¢ƒ
conda activate llava15
```

### Step 2: å®‰è£ PyTorch

```bash
# å®‰è£ PyTorchï¼ˆCUDA 11.8 ç‰ˆæœ¬ï¼Œæ ¹æ“šä½ çš„ CUDA ç‰ˆæœ¬èª¿æ•´ï¼‰
pip install torch==2.1.0 torchvision==0.16.0 torchaudio==2.1.0 --index-url https://download.pytorch.org/whl/cu118

# æˆ–è€… CUDA 12.1 ç‰ˆæœ¬
# pip install torch==2.1.0 torchvision==0.16.0 torchaudio==2.1.0 --index-url https://download.pytorch.org/whl/cu121

# é©—è­‰ PyTorch å®‰è£
python -c "import torch; print(f'PyTorch: {torch.__version__}'); print(f'CUDA available: {torch.cuda.is_available()}')"
```

### Step 3: Clone LLaVA Repository

```bash
# é€²å…¥ä½ çš„å·¥ä½œç›®éŒ„
cd /tmp2/b12902041/Gino/ShuoIsAllYouNeed/Yao/final/CLD

# Clone LLaVA
git clone https://github.com/haotian-liu/LLaVA.git
cd LLaVA

# æˆ–è€…ä½¿ç”¨ç‰¹å®šç‰ˆæœ¬ï¼ˆæ›´ç©©å®šï¼‰
# git clone -b v1.2.0 https://github.com/haotian-liu/LLaVA.git
```

### Step 4: å®‰è£ LLaVA ä¾è³´

```bash
# ç¢ºä¿åœ¨ llava15 ç’°å¢ƒä¸­
conda activate llava15

# é€²å…¥ LLaVA ç›®éŒ„
cd /tmp2/b12902041/Gino/ShuoIsAllYouNeed/Yao/final/CLD/LLaVA

# å®‰è£ä¾è³´
pip install --upgrade pip
pip install -e .

# å¦‚æœä¸Šé¢å¤±æ•—ï¼Œå˜—è©¦ï¼š
# pip install -e ".[train]"
```

### Step 5: å®‰è£é¡å¤–ä¾è³´

```bash
# å®‰è£å…¶ä»–éœ€è¦çš„åŒ…
pip install datasets
pip install pyarrow
pip install fastparquet
pip install transformers
pip install accelerate
pip install bitsandbytes  # ç”¨æ–¼ 4-bit/8-bit é‡åŒ–
pip install sentencepiece
pip install protobuf
```

### Step 6: é©—è­‰å®‰è£

```bash
python -c "
from llava.model.builder import load_pretrained_model
print('âœ… LLaVA æ¨¡çµ„å¯ä»¥å°å…¥ï¼')
"
```

### Step 7: ä¿®æ”¹ Caption ç”Ÿæˆè…³æœ¬

**ä¿®æ”¹ `generate_captions_for_training.py` ç¬¬ 20 è¡Œ**ï¼š

```python
# åŸä¾†
LLAVA_DIR = Path("/tmp2/b12902041/Gino/dlcv-fall-2025-final-project/third_party/llava")

# æ”¹ç‚ºä½ çš„ LLaVA è·¯å¾‘
LLAVA_DIR = Path("/tmp2/b12902041/Gino/ShuoIsAllYouNeed/Yao/final/CLD/LLaVA")
```

---

## ğŸ”§ æ–¹æ¡ˆ A: ä½¿ç”¨ç¾æœ‰çš„ LLaVA ç’°å¢ƒ

å¦‚æœå°ˆæ¡ˆä¸­å·²ç¶“æœ‰ LLaVA ç’°å¢ƒï¼š

```bash
# æª¢æŸ¥ç’°å¢ƒ
conda env list | grep llava

# å•Ÿå‹•ç’°å¢ƒï¼ˆåç¨±å¯èƒ½æ˜¯ llava, llava15, æˆ–å…¶ä»–ï¼‰
conda activate llava15  # æˆ– conda activate llava

# æ¸¬è©¦
python -c "
import sys
sys.path.insert(0, '/tmp2/b12902041/Gino/dlcv-fall-2025-final-project/third_party/llava')
from llava.model.builder import load_pretrained_model
print('âœ… LLaVA å¯ç”¨ï¼')
"
```

---

## ğŸ“¦ ç°¡åŒ–ç‰ˆå®‰è£ï¼ˆæœ€å°ä¾è³´ï¼‰

å¦‚æœåªæ˜¯è¦ç”Ÿæˆ captionï¼Œå¯ä»¥ç”¨æ›´ç°¡å–®çš„æ–¹å¼ï¼š

```bash
# å‰µå»ºç’°å¢ƒ
conda create -n llava_simple python=3.10 -y
conda activate llava_simple

# å®‰è£ PyTorch
pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118

# Clone ä¸¦å®‰è£ LLaVA
cd /tmp2/b12902041/Gino/ShuoIsAllYouNeed/Yao/final/CLD
git clone https://github.com/haotian-liu/LLaVA.git
cd LLaVA
pip install -e .

# å®‰è£å¿…è¦çš„åŒ…
pip install datasets transformers accelerate bitsandbytes protobuf sentencepiece
```

---

## ğŸ› å¸¸è¦‹å•é¡Œæ’æŸ¥

### Q1: `import llava` å¤±æ•—

**æª¢æŸ¥**ï¼š
```bash
# ç¢ºèªç’°å¢ƒ
conda activate llava15

# æª¢æŸ¥ LLAVA_DIR è·¯å¾‘
ls /tmp2/b12902041/Gino/ShuoIsAllYouNeed/Yao/final/CLD/LLaVA

# æ‰‹å‹•æ·»åŠ è·¯å¾‘æ¸¬è©¦
python -c "
import sys
sys.path.insert(0, '/path/to/LLaVA')
from llava.model.builder import load_pretrained_model
print('æˆåŠŸï¼')
"
```

### Q2: CUDA ä¸å¯ç”¨

**æª¢æŸ¥**ï¼š
```bash
python -c "import torch; print(torch.cuda.is_available())"

# å¦‚æœæ˜¯ Falseï¼Œæª¢æŸ¥ CUDA ç‰ˆæœ¬
nvcc --version

# é‡æ–°å®‰è£å°æ‡‰ç‰ˆæœ¬çš„ PyTorch
```

### Q3: é¡¯å­˜ä¸è¶³

**è§£æ±ºæ–¹æ¡ˆ**ï¼š
```bash
# åœ¨ generate_captions_for_training.py ä¸­ä½¿ç”¨ 4-bit é‡åŒ–
python generate_captions_for_training.py \
    --load_4bit \
    ...
```

### Q4: `bitsandbytes` å®‰è£å¤±æ•—

**Linux**ï¼š
```bash
pip install bitsandbytes
```

**å¦‚æœå¤±æ•—**ï¼š
```bash
# å¾æºç¢¼å®‰è£
pip install git+https://github.com/TimDettmers/bitsandbytes.git
```

### Q5: æ¨¡å‹ä¸‹è¼‰å¾ˆæ…¢

**ä½¿ç”¨ HuggingFace é¡åƒ**ï¼š
```bash
# è¨­ç½®ç’°å¢ƒè®Šé‡
export HF_ENDPOINT=https://hf-mirror.com

# æˆ–åœ¨ Python ä¸­
import os
os.environ['HF_ENDPOINT'] = 'https://hf-mirror.com'
```

---

## ğŸ¯ å¿«é€Ÿé©—è­‰æ¸…å–®

å®‰è£å®Œæˆå¾Œï¼Œé‹è¡Œé€™äº›æ¸¬è©¦ï¼š

```bash
# 1. å•Ÿå‹•ç’°å¢ƒ
conda activate llava15

# 2. æ¸¬è©¦ PyTorch
python -c "import torch; print(f'PyTorch: {torch.__version__}, CUDA: {torch.cuda.is_available()}')"

# 3. æ¸¬è©¦ LLaVA å°å…¥
python -c "
import sys
sys.path.insert(0, '/tmp2/b12902041/Gino/ShuoIsAllYouNeed/Yao/final/CLD/LLaVA')
from llava.model.builder import load_pretrained_model
from llava.utils import disable_torch_init
print('âœ… LLaVA æ¨¡çµ„æ­£å¸¸ï¼')
"

# 4. æ¸¬è©¦å…¶ä»–ä¾è³´
python -c "
from datasets import load_dataset
from PIL import Image
from transformers import AutoTokenizer
print('âœ… æ‰€æœ‰ä¾è³´æ­£å¸¸ï¼')
"

# 5. æ¸¬è©¦ Caption è…³æœ¬ï¼ˆ10 å€‹æ¨£æœ¬ï¼‰
cd /tmp2/b12902041/Gino/ShuoIsAllYouNeed/Yao/final/CLD
python generate_captions_for_training.py \
    --data_dir /tmp2/b12902041/Gino/cld_dataset/snapshots/snapshot_1/data \
    --output test_caption.json \
    --max_samples 10
```

---

## ğŸ“Š ç³»çµ±éœ€æ±‚

### ç¡¬é«”éœ€æ±‚
- **GPU**: NVIDIA GPU with â‰¥ 16GB VRAMï¼ˆæ¨è–¦ 24GB+ï¼‰
- **RAM**: â‰¥ 32GB
- **Storage**: â‰¥ 50GBï¼ˆfor model cacheï¼‰

### è»Ÿé«”éœ€æ±‚
- **OS**: Linuxï¼ˆæ¨è–¦ Ubuntu 20.04+ï¼‰
- **CUDA**: 11.7+ æˆ– 12.1+
- **Python**: 3.9 æˆ– 3.10
- **Conda**: Miniconda æˆ– Anaconda

---

## ğŸ‰ å®‰è£å®Œæˆå¾Œ

å®Œæˆå¾Œä½ æ‡‰è©²æœ‰ï¼š

```bash
# ç’°å¢ƒ
llava15 (Python 3.10)

# LLaVA codebase
/tmp2/b12902041/Gino/ShuoIsAllYouNeed/Yao/final/CLD/LLaVA/

# å¯ä»¥é‹è¡Œ
python generate_captions_for_training.py --help
```

**ç¾åœ¨å¯ä»¥é–‹å§‹ç”Ÿæˆ captions äº†ï¼** ğŸš€

---

## ğŸ’¡ æ¨è–¦çš„å®Œæ•´æµç¨‹

```bash
# 1. å®‰è£ç’°å¢ƒï¼ˆä¸€æ¬¡æ€§ï¼‰
conda create -n llava15 python=3.10 -y
conda activate llava15
pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118

# 2. Clone LLaVA
cd /tmp2/b12902041/Gino/ShuoIsAllYouNeed/Yao/final/CLD
git clone https://github.com/haotian-liu/LLaVA.git
cd LLaVA
pip install -e .
pip install datasets transformers accelerate bitsandbytes protobuf sentencepiece

# 3. ä¿®æ”¹è…³æœ¬ä¸­çš„ LLAVA_DIR è·¯å¾‘

# 4. æ¸¬è©¦
cd /tmp2/b12902041/Gino/ShuoIsAllYouNeed/Yao/final/CLD
python generate_captions_for_training.py \
    --data_dir /tmp2/b12902041/Gino/cld_dataset/snapshots/snapshot_1/data \
    --output test.json \
    --max_samples 2

# 5. å…¨é‡ç”Ÿæˆ
python generate_captions_for_training.py \
    --data_dir /tmp2/b12902041/Gino/cld_dataset/snapshots/snapshot_1/data \
    --output caption_mapping_full.json
```

**ç¥å®‰è£é †åˆ©ï¼** ğŸŠ

