#!/usr/bin/env python3
"""
å°‡ TAData çš„ parquet è½‰æ›ç‚ºåŸºæ–¼è·¯å¾‘çš„ç‰ˆæœ¬
- æŠŠ preview Image å°è±¡ä¿å­˜ç‚ºæ–‡ä»¶
- æŠŠ image list (layer images) ä¿å­˜ç‚ºæ–‡ä»¶
- ç”Ÿæˆæ–°çš„ parquetï¼Œpreview å’Œ image éƒ½æ˜¯è·¯å¾‘å­—ç¬¦ä¸²

é€™æ¨£å°±å¯ä»¥ç”¨ caption_mapping.json äº†ï¼
"""

import os
import sys
from pathlib import Path
from datasets import load_dataset, Dataset
from PIL import Image
import pandas as pd
from tqdm import tqdm

def convert_tadata_to_path_based(
    input_parquet_dir: str,
    output_dir: str,
    images_output_dir: str,
):
    """
    è½‰æ› TAData parquet ç‚ºåŸºæ–¼è·¯å¾‘çš„ç‰ˆæœ¬
    
    Args:
        input_parquet_dir: TAData parquet æ–‡ä»¶ç›®éŒ„
        output_dir: è¼¸å‡º parquet æ–‡ä»¶ç›®éŒ„
        images_output_dir: è¼¸å‡ºåœ–ç‰‡æ–‡ä»¶ç›®éŒ„
    """
    input_dir = Path(input_parquet_dir)
    output_dir = Path(output_dir)
    images_dir = Path(images_output_dir)
    
    # å»ºç«‹è¼¸å‡ºç›®éŒ„
    output_dir.mkdir(parents=True, exist_ok=True)
    images_dir.mkdir(parents=True, exist_ok=True)
    
    # å»ºç«‹å­ç›®éŒ„
    preview_dir = images_dir / "previews"
    layers_dir = images_dir / "layers"
    preview_dir.mkdir(exist_ok=True)
    layers_dir.mkdir(exist_ok=True)
    
    # æ‰¾åˆ°æ‰€æœ‰ parquet æ–‡ä»¶
    parquet_files = sorted(list(input_dir.glob("*.parquet")))
    print(f"æ‰¾åˆ° {len(parquet_files)} å€‹ parquet æ–‡ä»¶")
    
    for pf in parquet_files:
        print(f"\nè™•ç† {pf.name}...")
        
        # è¼‰å…¥ dataset
        ds = load_dataset('parquet', data_files=str(pf))['train']
        print(f"  è¼‰å…¥ {len(ds)} å€‹æ¨£æœ¬")
        
        # è½‰æ›æ¯å€‹æ¨£æœ¬
        records = []
        
        for i in tqdm(range(len(ds)), desc="  è½‰æ›æ¨£æœ¬"):
            item = ds[i]
            
            # ç”Ÿæˆå”¯ä¸€ IDï¼ˆä½¿ç”¨åŸå§‹ id æˆ– indexï¼‰
            sample_id = item.get('id', f"sample_{i:08d}")
            
            # 1. ä¿å­˜ preview åœ–ç‰‡
            preview_img = item['preview']
            if isinstance(preview_img, Image.Image):
                preview_filename = f"{sample_id}_preview.png"
                preview_path = preview_dir / preview_filename
                preview_img.save(preview_path)
                preview_path_str = str(preview_path.absolute())
            else:
                # å·²ç¶“æ˜¯è·¯å¾‘
                preview_path_str = preview_img
            
            # 2. ä¿å­˜æ¯å€‹ layer åœ–ç‰‡
            layer_images = item['image']
            layer_paths = []
            
            if isinstance(layer_images, list):
                for layer_idx, layer_img in enumerate(layer_images):
                    if layer_img is None:
                        layer_paths.append(None)
                    elif isinstance(layer_img, Image.Image):
                        layer_filename = f"{sample_id}_layer_{layer_idx:02d}.png"
                        layer_path = layers_dir / layer_filename
                        layer_img.save(layer_path)
                        layer_paths.append(str(layer_path.absolute()))
                    else:
                        # å·²ç¶“æ˜¯è·¯å¾‘
                        layer_paths.append(layer_img)
            else:
                layer_paths = layer_images
            
            # 3. å»ºç«‹æ–°è¨˜éŒ„ï¼ˆä¿ç•™æ‰€æœ‰åŸå§‹æ¬„ä½ï¼Œåªä¿®æ”¹ preview å’Œ imageï¼‰
            record = dict(item)
            record['preview'] = preview_path_str
            record['image'] = layer_paths
            
            records.append(record)
        
        # ä¿å­˜ç‚ºæ–°çš„ parquet
        df = pd.DataFrame(records)
        output_parquet = output_dir / pf.name
        df.to_parquet(output_parquet, index=False, engine='pyarrow')
        print(f"  âœ“ ä¿å­˜åˆ° {output_parquet}")
    
    print(f"\nâœ… è½‰æ›å®Œæˆï¼")
    print(f"  æ–° parquet: {output_dir}")
    print(f"  åœ–ç‰‡æ–‡ä»¶: {images_dir}")
    print(f"\nğŸ’¡ ç¾åœ¨å¯ä»¥ç”¨é€™å€‹ dataset é…åˆ caption_mapping.jsonï¼")


if __name__ == "__main__":
    import argparse
    
    parser = argparse.ArgumentParser(description="è½‰æ› TAData ç‚ºåŸºæ–¼è·¯å¾‘çš„ç‰ˆæœ¬")
    parser.add_argument(
        "--input_dir",
        type=str,
        default="/tmp2/b12902041/Gino/TAData/DLCV_dataset/data",
        help="TAData parquet ç›®éŒ„"
    )
    parser.add_argument(
        "--output_dir",
        type=str,
        default="/tmp2/b12902041/Gino/TAData_with_paths/data",
        help="è¼¸å‡º parquet ç›®éŒ„"
    )
    parser.add_argument(
        "--images_dir",
        type=str,
        default="/tmp2/b12902041/Gino/TAData_with_paths/images",
        help="è¼¸å‡ºåœ–ç‰‡ç›®éŒ„"
    )
    
    args = parser.parse_args()
    
    convert_tadata_to_path_based(
        input_parquet_dir=args.input_dir,
        output_dir=args.output_dir,
        images_output_dir=args.images_dir,
    )
