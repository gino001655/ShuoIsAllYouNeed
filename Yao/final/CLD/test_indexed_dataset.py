"""
æ¸¬è©¦ index-based caption matching æ–¹æ¡ˆ
"""

import sys
sys.path.insert(0, '/tmp2/b12902041/Gino/ShuoIsAllYouNeed/Yao/final/CLD/tools')

from dlcv_dataset_indexed import DLCVLayoutDatasetIndexed, collate_fn
from torch.utils.data import DataLoader


def test_indexed_dataset():
    """æ¸¬è©¦ indexed dataset"""
    
    print("="*60)
    print("æ¸¬è©¦æ–¹æ¡ˆ B: Index-based Caption Matching")
    print("="*60)
    
    # è¨­å®šè·¯å¾‘
    data_dir = "/tmp2/b12902041/Gino/TAData/DLCV_dataset/data"
    caption_json = "/tmp2/b12902041/Gino/ShuoIsAllYouNeed/Yao/final/CLD/caption_llava16_final.json"
    
    print(f"\n1. è¼‰å…¥ dataset...")
    print(f"   Data dir: {data_dir}")
    print(f"   Caption JSON: {caption_json}")
    
    # å‰µå»º dataset
    dataset = DLCVLayoutDatasetIndexed(
        data_dir=data_dir,
        caption_json_path=caption_json,
        enable_debug=True,  # é¡¯ç¤ºå‰ 3 å€‹æ¨£æœ¬çš„ debug è³‡è¨Š
    )
    
    print(f"\n2. Dataset è³‡è¨Š:")
    print(f"   ç¸½æ¨£æœ¬æ•¸: {len(dataset)}")
    
    # æ¸¬è©¦å‰ 3 å€‹æ¨£æœ¬
    print(f"\n3. æ¸¬è©¦å‰ 3 å€‹æ¨£æœ¬...")
    
    for i in range(min(3, len(dataset))):
        sample = dataset[i]
        
        print(f"\n--- Sample {i} ---")
        print(f"Preview size: {sample['whole_img'].size}")
        print(f"Canvas size: {sample['width']} x {sample['height']}")
        print(f"Number of layers: {len(sample['layout'])}")
        print(f"Caption (å‰ 150 å­—): {sample['caption'][:150]}...")
        
        # æª¢æŸ¥ layers
        for j, layer in enumerate(sample['layout'][:5]):  # åªé¡¯ç¤ºå‰ 5 å€‹ layer
            print(f"  Layer {j}: {layer['layer_img'].size}, bbox=({layer['left']}, {layer['top']}, {layer['width']}, {layer['height']})")
    
    # æ¸¬è©¦ DataLoader
    print(f"\n4. æ¸¬è©¦ DataLoader...")
    
    loader = DataLoader(
        dataset,
        batch_size=1,
        shuffle=False,
        collate_fn=collate_fn,
        num_workers=0,
    )
    
    print(f"   å‰µå»º DataLoader æˆåŠŸ (batch_size=1)")
    
    # æ¸¬è©¦è¿­ä»£
    print(f"\n5. æ¸¬è©¦è¿­ä»£å‰ 2 å€‹ batch...")
    
    for i, batch in enumerate(loader):
        if i >= 2:
            break
        
        print(f"\nBatch {i}:")
        print(f"  Type: {type(batch)}")
        print(f"  Keys: {batch.keys() if isinstance(batch, dict) else 'N/A'}")
        print(f"  Preview type: {type(batch['whole_img'])}")
        print(f"  Caption length: {len(batch['caption'])}")
        print(f"  Layers: {len(batch['layout'])}")
    
    print("\n" + "="*60)
    print("âœ“ æ¸¬è©¦å®Œæˆï¼")
    print("="*60)
    
    # çµ±è¨ˆè³‡è¨Š
    print(f"\nğŸ“Š çµ±è¨ˆè³‡è¨Š:")
    
    num_samples_to_check = min(10, len(dataset))
    layer_counts = []
    caption_lengths = []
    
    for i in range(num_samples_to_check):
        sample = dataset[i]
        layer_counts.append(len(sample['layout']))
        caption_lengths.append(len(sample['caption']))
    
    print(f"   æª¢æŸ¥å‰ {num_samples_to_check} å€‹æ¨£æœ¬:")
    print(f"   - å¹³å‡ layer æ•¸: {sum(layer_counts) / len(layer_counts):.1f}")
    print(f"   - Layer æ•¸ç¯„åœ: {min(layer_counts)} ~ {max(layer_counts)}")
    print(f"   - å¹³å‡ caption é•·åº¦: {sum(caption_lengths) / len(caption_lengths):.0f} å­—å…ƒ")
    print(f"   - Caption é•·åº¦ç¯„åœ: {min(caption_lengths)} ~ {max(caption_lengths)} å­—å…ƒ")
    
    print("\nğŸ‰ æ–¹æ¡ˆ B å¯è¡Œï¼ä¸éœ€è¦è½‰æ›æ•¸æ“šé›†ï¼")


if __name__ == '__main__':
    test_indexed_dataset()

