# 訓練配置：使用方案 B (Index-based TAData + LLaVA captions)
# 不需要轉換數據集，直接使用 TAData + caption.json

seed: 42
max_layer_num: 52
num_inference_steps: 28

lora_rank: 64
lora_alpha: 64
lora_dropout: 0

max_steps: 20000
log_every: 1000
save_every: 200
max_sequence_length: 512  # 減少文本長度可以節省 VRAM（從 512 降到 256 可節省約 50% 的 prompt_embeds 記憶體）
cfg: 4.0
accum_steps: 2
optimizer: Prodigy

# VRAM 優化設定
enable_memory_cleanup: true  # 啟用記憶體清理（釋放中間變數，清理碎片）
# 圖像縮放（可選，進一步減少 VRAM）
# resize_training_images: false  # 設為 true 啟用圖像縮放
# max_training_image_size: 1536  # 訓練時最大圖像尺寸（單邊，單位：px）

adapter_scale: 0.9

# ⭐ 方案 B 配置：使用 TAData + caption.json
# Training 使用 DLCVLayoutDataset（支持 caption_mapping），不用 indexed dataset
# indexed dataset 只用於 inference
use_indexed_dataset: false  # Training 不用 indexed dataset
data_dir: "/workspace/dataset/DLCV_dataset"  # TAData 目錄（指向 data/ 子目錄）
caption_mapping: "/workspace/ShuoIsAllYouNeed/Yao/final/CLD/caption_llava16_final.json"  # LLaVA captions

# Debug 設定
enable_dataset_debug: true  # 顯示前 3 個樣本的詳細載入資訊
skip_unk_captions: true
unk_token: "<unk>"
unk_skip_min_count: 1

# 大樣本過濾設定（減少 VRAM 消耗）
skip_large_samples: false  # 設為 true 啟用過濾
max_layers: 10  # 最大 Layer 數（建議根據統計結果設定，如 95% 百分位數）
max_image_size: 1024  # 最大圖像尺寸（單邊，單位：px，建議 2048 或 1536）
max_total_pixels: 1048576  # 最大總像素數（寬×高，2048×2048=4194304，建議根據統計結果設定）

# Multi-GPU 設定
use_multi_gpu: false  # 設為 true 啟用 DataParallel（需要 2+ GPUs）

# 模型路徑（根據你的環境調整）
artplus_lora_dir: "/workspace/ShuoIsAllYouNeed/Yao/final/CLD/ckpt/prism_ft_LoRA"
resume_from: "/workspace/ShuoIsAllYouNeed/Yao/final/CLD/ckpt/decouple_LoRA"

pretrained_model_name_or_path: "flux_model"
pretrained_adapter_path: "Path_to_pretrained_FLUX_adapter"
pretrained_lora_dir: "ckpt/pre_trained_LoRA"
output_dir: "FT_on_TAData_ckpt"

